{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    words = []\n",
    "    for word in text.split():\n",
    "        if word.lower() not in sw:\n",
    "            cleaned = re.sub('[\\,.\\'\\(\\);\\/\\*:\\\"\\[\\]]', '', word)\n",
    "            if cleaned:\n",
    "                words += [cleaned]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, n):\n",
    "        self.words = defaultdict(int)\n",
    "        self.n = n\n",
    "        self.freq = 0\n",
    "        \n",
    "    def add_word(self, word):\n",
    "        self.words[word] += 1\n",
    "        self.freq += 1\n",
    "        return self.update_set()\n",
    "    \n",
    "    def add_words(self, lst):\n",
    "        for word in lst:\n",
    "            self.words[word] += 1\n",
    "            self.freq += 1\n",
    "        return self.update_set()\n",
    "    \n",
    "    def update_set(self):\n",
    "        \"\"\"Maintains n words in the cluster\"\"\"\n",
    "        lst = []\n",
    "        while len(self.words) > self.n:\n",
    "            srt = sorted(self.words.items(), key=lambda kv: kv[1])\n",
    "            self.words.pop(srt[0][0])\n",
    "            lst += (srt[0][0])\n",
    "            self.freq -= srt[0][1]\n",
    "        return lst\n",
    "    \n",
    "    def get_words(self):\n",
    "        return set(self.words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Five score years ago, a great American, in whose symbolic shadow we stand today, signed the Emancipation Proclamation. \\\n",
    "This momentous decree came as a great beacon light of hope to millions of Negro slaves who had been seared in the flames of \\\n",
    "withering injustice. It came as a joyous daybreak to end the long night of their captivity. \\\n",
    "But one hundred years later, the Negro still is not free; one hundred years later, the life of the Negro is still sadly \\\n",
    "crippled by the manacles of segregation and the chains of discrimination; one hundred years later, the Negro lives on a \\\n",
    "lonely island of poverty in the midst of a vast ocean of material prosperity; one hundred years later, the Negro is still \\\n",
    "languished in the corners of American society and finds himself in exile in his own land\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "DIFF_THRESH = 4\n",
    "\n",
    "word_bag = defaultdict(list)\n",
    "cluster_list = []\n",
    "\n",
    "words = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_cluster(window):\n",
    "    b = None\n",
    "    thresh = DIFF_THRESH\n",
    "    chk_set = set(window)\n",
    "    for word in window:\n",
    "        for cluster in word_bag[word]:\n",
    "            # check overlap between window and cluster\n",
    "            chk = len(chk_set.intersection(cluster.get_words()))\n",
    "            if chk >= thresh:\n",
    "                b = cluster\n",
    "                thresh = chk\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Five', 'score', 'years', 'ago', 'great', 'American']\n",
      "['whose', 'symbolic', 'shadow', 'stand', 'today', 'signed']\n",
      "['Emancipation', 'Proclamation', 'momentous', 'decree', 'came', 'great']\n",
      "['beacon', 'light', 'hope', 'millions', 'Negro', 'slaves']\n",
      "['seared', 'flames', 'withering', 'injustice', 'came', 'joyous']\n",
      "['daybreak', 'end', 'long', 'night', 'captivity', 'one']\n",
      "['hundred', 'years', 'later', 'Negro', 'still', 'free']\n",
      "['one', 'hundred', 'years', 'later', 'life', 'Negro']\n",
      "['still', 'sadly', 'crippled', 'manacles', 'segregation', 'chains']\n",
      "['discrimination', 'one', 'hundred', 'years', 'later', 'Negro']\n",
      "['lives', 'lonely', 'island', 'poverty', 'midst', 'vast']\n",
      "['ocean', 'material', 'prosperity', 'one', 'hundred', 'years']\n",
      "['later', 'Negro', 'still', 'languished', 'corners', 'American']\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(K/2), len(words)-1, K):\n",
    "    window = []\n",
    "    for j in range(int(-K/2), int(K/2)):\n",
    "        window += [words[i+j]]\n",
    "    print(window)\n",
    "    cluster = best_cluster(window)\n",
    "    if not cluster: # if no best cluster found, create new cluster\n",
    "        cluster = Cluster(K)\n",
    "        cluster_list += [cluster]\n",
    "    removed = set(cluster.add_words(window))\n",
    "    for word in window:\n",
    "        if word in removed:\n",
    "            word_bag[word].remove(cluster)\n",
    "        elif cluster not in word_bag[word]:\n",
    "            word_bag[word] += [cluster]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'years', 'Five', 'score', 'great', 'American', 'ago'} 6\n",
      "{'today', 'stand', 'signed', 'whose', 'symbolic', 'shadow'} 6\n",
      "{'decree', 'momentous', 'great', 'came', 'Proclamation', 'Emancipation'} 6\n",
      "{'hope', 'slaves', 'light', 'Negro', 'millions', 'beacon'} 6\n",
      "{'came', 'injustice', 'flames', 'seared', 'joyous', 'withering'} 6\n",
      "{'night', 'captivity', 'long', 'daybreak', 'end', 'one'} 6\n",
      "{'years', 'Negro', 'discrimination', 'hundred', 'later', 'one'} 15\n",
      "{'chains', 'still', 'manacles', 'segregation', 'sadly', 'crippled'} 6\n",
      "{'lives', 'lonely', 'poverty', 'island', 'midst', 'vast'} 6\n",
      "{'years', 'material', 'hundred', 'prosperity', 'ocean', 'one'} 6\n",
      "{'still', 'Negro', 'languished', 'later', 'American', 'corners'} 6\n"
     ]
    }
   ],
   "source": [
    "for cluster in cluster_list:\n",
    "    print(cluster.get_words(), cluster.freq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
